{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M0NEp-_Gu4h4"
      },
      "source": [
        "# Bert NER using BIO format\n",
        "This notebook follows the tutorial: https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/?fbclid=IwAR0jI8JgegMSVJ_5k2i4hzlyedLxmR0UuPzjfK8LavaO7z3yUqNRRJiJsr4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UyVXvl_9xSZn"
      },
      "source": [
        "##Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GSeJfA1lxbCs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: NVIDIA RTX A5000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "\n",
        "MAX_LEN = 75\n",
        "bs = 32\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    # Set the device to a specific GPU, e.g., GPU 0\n",
        "    device = torch.device(\"cuda:1\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(1)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5xQWnjo9fdv9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.6.0\n",
            "  Using cached transformers-2.6.0-py3-none-any.whl (540 kB)\n",
            "Requirement already satisfied: numpy in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from transformers==2.6.0) (1.25.0)\n",
            "Collecting tokenizers==0.5.2 (from transformers==2.6.0)\n",
            "  Using cached tokenizers-0.5.2.tar.gz (64 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting boto3 (from transformers==2.6.0)\n",
            "  Downloading boto3-1.34.11-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from transformers==2.6.0) (3.9.0)\n",
            "Requirement already satisfied: requests in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from transformers==2.6.0) (2.29.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from transformers==2.6.0) (4.66.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from transformers==2.6.0) (2023.12.25)\n",
            "Collecting sentencepiece (from transformers==2.6.0)\n",
            "  Using cached sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting sacremoses (from transformers==2.6.0)\n",
            "  Using cached sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "Collecting botocore<1.35.0,>=1.34.11 (from boto3->transformers==2.6.0)\n",
            "  Downloading botocore-1.34.11-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->transformers==2.6.0)\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->transformers==2.6.0)\n",
            "  Using cached s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from requests->transformers==2.6.0) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from requests->transformers==2.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from requests->transformers==2.6.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from requests->transformers==2.6.0) (2023.7.22)\n",
            "Requirement already satisfied: click in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from sacremoses->transformers==2.6.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from sacremoses->transformers==2.6.0) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.11->boto3->transformers==2.6.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.11->boto3->transformers==2.6.0) (1.16.0)\n",
            "Building wheels for collected packages: tokenizers\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[46 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m running bdist_wheel\n",
            "  \u001b[31m   \u001b[0m running build\n",
            "  \u001b[31m   \u001b[0m running build_py\n",
            "  \u001b[31m   \u001b[0m creating build\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/tokenizers\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-311/tokenizers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/tokenizers/models\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/models/__init__.py -> build/lib.linux-x86_64-cpython-311/tokenizers/models\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/tokenizers/decoders\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/decoders/__init__.py -> build/lib.linux-x86_64-cpython-311/tokenizers/decoders\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/tokenizers/normalizers\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/normalizers/__init__.py -> build/lib.linux-x86_64-cpython-311/tokenizers/normalizers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/tokenizers/pre_tokenizers\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/pre_tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-311/tokenizers/pre_tokenizers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/tokenizers/processors\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/processors/__init__.py -> build/lib.linux-x86_64-cpython-311/tokenizers/processors\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/tokenizers/trainers\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/trainers/__init__.py -> build/lib.linux-x86_64-cpython-311/tokenizers/trainers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/implementations/char_level_bpe.py -> build/lib.linux-x86_64-cpython-311/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/implementations/bert_wordpiece.py -> build/lib.linux-x86_64-cpython-311/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/implementations/base_tokenizer.py -> build/lib.linux-x86_64-cpython-311/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/implementations/sentencepiece_bpe.py -> build/lib.linux-x86_64-cpython-311/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/implementations/byte_level_bpe.py -> build/lib.linux-x86_64-cpython-311/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/implementations/__init__.py -> build/lib.linux-x86_64-cpython-311/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-311/tokenizers\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/models/__init__.pyi -> build/lib.linux-x86_64-cpython-311/tokenizers/models\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/decoders/__init__.pyi -> build/lib.linux-x86_64-cpython-311/tokenizers/decoders\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/normalizers/__init__.pyi -> build/lib.linux-x86_64-cpython-311/tokenizers/normalizers\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/pre_tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-311/tokenizers/pre_tokenizers\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/processors/__init__.pyi -> build/lib.linux-x86_64-cpython-311/tokenizers/processors\n",
            "  \u001b[31m   \u001b[0m copying tokenizers/trainers/__init__.pyi -> build/lib.linux-x86_64-cpython-311/tokenizers/trainers\n",
            "  \u001b[31m   \u001b[0m running build_ext\n",
            "  \u001b[31m   \u001b[0m running build_rust\n",
            "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m To update pip, run:\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m and then retry package installation.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: seqeval in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from seqeval) (1.25.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from seqeval) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==2.6.0\n",
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "T4bS9315iU4-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5cZBjDEhjBp4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-03 13:24:21.663330: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-03 13:24:21.703366: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-03 13:24:21.703414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-03 13:24:21.704555: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-03 13:24:21.711139: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-03 13:24:22.399655: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from seqeval.metrics import f1_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import itertools\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "# Import necessary libraries for RoBERTa and DistilBERT\n",
        "from transformers import RobertaTokenizer, RobertaForTokenClassification\n",
        "from transformers import DistilBertTokenizer, DistilBertForTokenClassification\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "torch.__version__\n",
        "\n",
        "import transformers\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "transformers.__version__\n",
        "\n",
        "\n",
        "MAX_LEN = 75\n",
        "bs = 32\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#n_gpu = torch.cuda.device_count()\n",
        "\n",
        "#torch.cuda.get_device_name(0) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def debug_labels_and_tag2idx(labels, tag2idx):\n",
        "    print(\"Debugging Labels and Tag2Idx\")\n",
        "    missing_labels = set()\n",
        "    for label_group in labels:\n",
        "        for label in label_group:\n",
        "            if label not in tag2idx:\n",
        "                missing_labels.add(label)\n",
        "    print(\"Missing labels:\", missing_labels)\n",
        "    print(\"tag2idx:\", tag2idx)\n",
        "    \n",
        "# Enhanced Debugging Function\n",
        "def debug_before_padding(labels, tag2idx):\n",
        "    print(\"Debugging before Padding\")\n",
        "    print(\"Sample labels:\", labels[:5])  # Print first 5 label groups for brevity\n",
        "    print(\"tag2idx:\", tag2idx)\n",
        "\n",
        "    # Checking for None values\n",
        "    for label_group in labels:\n",
        "        for label in label_group:\n",
        "            if tag2idx.get(label) is None:\n",
        "                print(f\"None value found for label: {label}\")\n",
        "                \n",
        "# Validate Labels\n",
        "def validate_labels(labels, tag2idx):\n",
        "    print(\"Validating Labels\")\n",
        "    for label_group in labels:\n",
        "        for label in label_group:\n",
        "            assert label in tag2idx, f\"Label '{label}' not in tag2idx\"\n",
        "\n",
        "# Model-Specific Adjustments\n",
        "def reset_model(model_name):\n",
        "    print(f\"Resetting model for {model_name}\")\n",
        "    # Add any specific reset steps if needed, like clearing cache or resetting states\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4It7G_1DxaHe"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "M0Agz90jn-Dw"
      },
      "outputs": [],
      "source": [
        "\n",
        "def transform_label(l): \n",
        "    return re.sub(r'^([BI]).*',r'\\1-FOOD',l)\n",
        "    \n",
        "\n",
        "def get_label(l):\n",
        "  return l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AspAIcmkm4jQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data, column, label_adapter=get_label):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "\n",
        "        self.grouped=[]\n",
        "        sentence=[]\n",
        "        for key,value in zip(data[column].keys(), data[column].values):\n",
        "          \n",
        "          sentence.append((key,label_adapter(value)))\n",
        "          if key == '.':\n",
        "            self.grouped.append(sentence)\n",
        "            sentence=[]\n",
        "        \n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GTQBJGDnlJIp"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_label_indices(train_data, test_data, label_adapter):\n",
        "  all_labels=[label_adapter(l) for l in itertools.chain(train_data[train_header].values, test_data[test_header].values)]\n",
        "  tag_values = list(set([label_adapter(l) for l in all_labels]))\n",
        "  tag_values.append(\"PAD\")\n",
        "  tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
        "  return tag_values, tag2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0G3pl-7tobfi"
      },
      "outputs": [],
      "source": [
        "def process_bio(data, column, label_adapter):\n",
        "  getter = SentenceGetter(data, column, label_adapter)\n",
        "\n",
        "  sentences = [[word[0] for word in sentence] for sentence in getter.sentences]\n",
        "\n",
        "\n",
        "  tag_values = list(set([label_adapter(l) for l in data[column].values]))\n",
        "  tag_values.append(\"PAD\")\n",
        "  tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
        "\n",
        "  labels = [[s[1] for s in sentence] for sentence in getter.sentences]\n",
        "  \n",
        "\n",
        "  return getter, sentences, tag_values, tag2idx, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8kxyLMrImdnt"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels,tokenizer):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sk7ayoaKtnUj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_model_and_tokenizer(model_name, num_labels):\n",
        "    if model_name == 'bert-base-cased':\n",
        "        tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
        "        model = BertForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "    elif model_name == 'roberta-base':\n",
        "        tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "        model = RobertaForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "    elif model_name == 'distilbert-base-uncased':\n",
        "        tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "        model = DistilBertForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "    # Additional cases for BioBERT or other models can be added here\n",
        "    else:\n",
        "        raise ValueError(\"Model not supported\")\n",
        "\n",
        "    return model, tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2_Ce212Fx_Nk"
      },
      "source": [
        "##Initializing torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gitASXScmbuB"
      },
      "outputs": [],
      "source": [
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "L1RvULO0Uvzb"
      },
      "outputs": [],
      "source": [
        "\n",
        "ds_tag_values = {\n",
        "    'food-classification': ['B-FOOD', 'I-FOOD', 'O', 'PAD'],\n",
        "    \"hansard-closest\": ['B-AG.01.n.04', 'I-AG.01.h.01.e', 'B-AF.12', 'I-AG.01.l.02', 'B-AG.01.d.07', 'B-AG.01.y.01', 'I-AG.01.p', 'B-AG.01.h.01.d', 'I-AG.01.y.01', 'B-AE.08.i', 'B-AG.01.h.02', 'B-AG.01.n.15', 'B-AG.01.g', 'I-AF.10.i', 'B-AG.01.h.01', 'B-AG.01.f', 'B-AG.01.ae.03', 'I-AG.01.e.02', 'I-AG.01.t.06', 'I-AG.01.t.05', 'B-AG.01.z', 'I-AG.01.n.09', 'B-AG.01', 'I-AG.01.l.03', 'B-AF.28', 'I-AG.01.t.08', 'I-AG.01.g', 'I-AG.01.h.01.c', 'I-AG.01.d.03', 'I-AG.01.h', 'B-AF.20.c', 'I-AG.01.t.07', 'B-AG.01.y.01.e', 'B-AF.20.b', 'B-AF.20.h', 'I-AG.01.j', 'B-AG.01.l.04', 'B-AG.01.n.02', 'I-AG.01.h.01', 'B-AG.01.h.01.b', 'I-AG.01', 'B-AG.01.h', 'B-AE.13.h.01', 'B-AG.01.h.02.e', 'B-AG.01.e.02', 'B-AG.01.h.01.a', 'B-AG.01.t.07', 'I-AG.01.l', 'B-AG.01.ad', 'O', 'I-AG.01.l.04', 'I-AG.01.o', 'I-AG.01.n.13', 'B-AG.01.t.05', 'B-AG.01.h.02.i', 'B-AG.01.n.16', 'I-AG.01.n.15', 'I-AG.01.n.03', 'I-AG.01.n.02', 'I-AG.01.m', 'B-AG.01.h.02.f', 'B-AG.01.n.13', 'B-AG.01.y.01.c', 'B-AG.01.d.04', 'I-AG.01.i', 'B-AG.01.h.01.f', 'I-AG.01.y.01.c', 'B-AG.01.ae.01', 'B-AF.20.g', 'B-AG.01.e', 'I-AG.01.h.02', 'I-AG.01.k', 'B-AE.10', 'B-AG.01.l.02', 'B-AG.01.h.02.h', 'B-AG.01.h.02.d', 'B-AG.01.n.14', 'I-AG.01.y.01.a', 'B-AG.01.d.05', 'I-AG.01.e', 'I-AG.01.h.02.e', 'B-AG.01.y.01.a', 'B-AG.01.i', 'I-AF.20.b', 'I-AG.01.n.11', 'B-AG.01.l.01', 'B-AG.01.h.01.e', 'B-AG.01.p', 'B-AG.01.y.01.b', 'I-AG.01.h.02.h', 'B-AG.01.j', 'B-AF.10.i', 'I-AF.02.a', 'B-AG.01.o', 'B-AG.01.d.02', 'I-AG.01.d.02', 'B-AG.01.m', 'B-AG.01.k', 'B-AG.01.d.03', 'B-AG.01.h.02.g', 'I-AG.01.n', 'I-AG.01.h.02.f', 'B-AG.01.h.02.b', 'I-AG.01.l.01', 'I-AG.01.z', 'I-AG.01.n.06', 'B-AG.01.d.06', 'I-AG.01.d.07', 'I-AG.01.ad', 'I-AG.01.h.02.i', 'I-AG.01.d.06', 'I-AG.01.n.14', 'B-AG.01.n', 'I-AG.01.e.01', 'B-AG.01.n.09', 'B-AE.08', 'I-AG.01.f', 'I-AG.01.h.02.b', 'B-AG.01.n.17.a', 'B-AG.01.ab', 'I-AG.01.h.02.c', 'I-AG.01.ab', 'I-AG.01.h.02.g', 'B-AG.01.h.02.c', 'B-AG.01.n.01', 'B-AG.01.t.08', 'B-AG.01.y.01.g', 'I-AF.20.g', 'I-AG.01.n.17.a', 'B-AG.01.ag', 'I-AG.01.n.05', 'B-AG.01.l.03', 'B-AG.01.n.05', 'I-AG.01.n.01', 'I-AG.01.h.01.b', 'B-AG.01.n.03', 'I-AG.01.ae.01', 'B-AG.01.y.01.f', 'I-AG.01.h.01.a', 'B-AG.01.u', 'B-AG.01.h.02.a', 'B-AG.01.h.01.c', 'B-AE.10.g', 'B-AF.20.e', 'B-AF.13', 'I-AG.01.h.02.a', 'B-AG.01.ac', 'B-AG.01.n.11', 'I-AG.01.y.01.g', 'B-AG.01.t.06', 'B-AG.01.e.01', 'I-AG.01.n.12', 'B-AG.01.d', 'B-AG.01.n.12', 'B-AF.02.a', 'I-AG.01.ac', 'I-AG.01.h.01.f', 'B-AG.01.n.06', 'I-AG.01.u', 'B-AG.01.l', 'I-AG.01.ag', 'I-AG.01.d.05', 'I-AG.01.ae.03', 'PAD'],\n",
        "    \"hansard-parent\": ['B-AG.01.a', 'B-AG.01.i', 'B-AF.12', 'B-AG.01.r', 'B-AE.08', 'I-AG.01.l', 'I-AG.01.f', 'B-AG.01.w', 'B-AF.10', 'B-AG.01.p', 'I-AG.01.r', 'I-AG.01.p', 'B-AG.01.t', 'O', 'B-AG.01.ad', 'I-AG.01.o', 'B-AG.01.j', 'B-AG.01.ae', 'B-AG.01.aa', 'B-AG.01.ab', 'B-AE.12', 'I-AG.01.ab', 'B-AG.01.g', 'I-AG.01.t', 'B-AG.01.f', 'I-AE.13', 'B-AG.01.h', 'I-AG.01.aa', 'B-AG.01.b', 'B-AG.01.z', 'B-AE.13', 'I-AG.01.m', 'B-AG.01.o', 'B-AG.01', 'B-AG.01.y', 'I-AF.02', 'B-AF.28', 'B-AG.01.m', 'I-AG.01.g', 'I-AG.01.i', 'B-AG.01.k', 'B-AF.02', 'I-AG.01.n', 'I-AG.01.y', 'I-AE.12', 'B-AG.01.e', 'I-AG.01.k', 'B-AE.10', 'I-AG.01.h', 'I-AG.01.ae', 'I-AF.10', 'I-AG.01.z', 'I-AG.01.a', 'B-AG.01.d', 'I-AE.10', 'I-AG.01.j', 'I-AG.01.ad', 'B-AF.20', 'I-AG.01', 'B-AG.01.l', 'I-AG.01.e', 'I-AG.01.d', 'B-AG.01.n', 'PAD'],\n",
        "    \"foodon\": ['B-NCBITaxon_49992', 'B-FOODON_03310272', 'I-NCBITaxon_4006', 'I-FOODON_03315188', 'I-hancestro_0383', 'I-CHEBI_24866', 'I-FOODON_03430137', 'I-FOODON_03305680', 'B-FOODON_03311869', 'B-FOODON_03307668', 'B-ENVO_00002006', 'B-FOODON_03302772', 'B-NCBITaxon_4530', 'I-FOODON_03302034', 'I-FOODON_03310273', 'B-FOODON_03530217', 'B-FOODON_03302904', 'B-FOODON_03310351', 'B-FOODON_03411328', 'B-FOODON_03304042', 'B-FOODON_03301072', 'I-ENVO_00002006', 'B-ENVO_01001125', 'I-FOODON_03315835', 'B-FOODON_03315597', 'B-FOODON_03311146', 'I-FOODON_03302908', 'I-FOODON_03315597', 'I-FOODON_03302458', 'B-FOODON_03303380', 'O', 'B-FOODON_03315647', 'B-FOODON_03301008', 'I-NCBITaxon_3888', 'B-FOODON_03307663', 'I-NCBITaxon_4530', 'B-NCBITaxon_16718', 'B-FOODON_03317455', 'I-NCBITaxon_4071', 'I-FOODON_03304010', 'B-NCBITaxon_4113', 'B-FOODON_03301217', 'B-FOODON_03301051', 'I-FOODON_03530020', 'I-NCBITaxon_381124', 'I-FOODON_03301614', 'I-FOODON_00002087', 'B-FOODON_03303659', 'B-NCBITaxon_22663', 'B-FOODON_03301614', 'I-NCBITaxon_34199', 'B-FOODON_03316070', 'I-FOODON_03301244', 'I-FOODON_03302835', 'I-FOODON_03315272', 'B-FOODON_03530021', 'B-FOODON_03307808', 'I-FOODON_03307280', 'I-FOODON_03303578', 'B-FOODON_03301505', 'I-FOODON_03301072', 'B-FOODON_03305236', 'B-CHEBI_24866', 'B-FOODON_03306616', 'I-FOODON_03301008', 'B-FOODON_03430137', 'I-NCBITaxon_59895', 'B-NCBITaxon_39350', 'B-FOODON_03305417', 'B-FOODON_03303508', 'I-FOODON_03420157', 'I-ENVO_01001125', 'I-FOODON_03317654', 'B-FOODON_03309491', 'B-FOODON_03315872', 'I-CHEBI_60004', 'I-FOODON_03303886', 'I-FOODON_03315872', 'B-FOODON_03310185', 'B-CHEBI_83163', 'I-UBERON_0001913', 'B-FOODON_03301441', 'B-NCBITaxon_13450', 'B-FOODON_03316347', 'I-FOODON_00001926', 'I-NCBITaxon_89151', 'I-FOODON_03301705', 'I-FOODON_03411044', 'B-FOODON_03305639', 'B-FOODON_03411269', 'I-FOODON_03301577', 'I-NCBITaxon_3755', 'I-NCBITaxon_22663', 'B-FOODON_03301842', 'I-FOODON_03302897', 'B-FOODON_03303578', 'I-FOODON_03301842', 'I-FOODON_03411669', 'B-NCBITaxon_4071', 'B-NCBITaxon_6563', 'B-FOODON_03305263', 'I-FOODON_03411335', 'B-NCBITaxon_4682', 'B-FOODON_03309457', 'I-FOODON_03302060', 'I-NCBITaxon_37656', 'I-FOODON_03301128', 'I-FOODON_03310689', 'I-FOODON_03305159', 'B-NCBITaxon_6566', 'B-UBERON_0001913', 'I-PO_0009001', 'I-NCBITaxon_4565', 'B-NCBITaxon_80379', 'I-FOODON_03310272', 'B-NCBITaxon_63459', 'I-NCBITaxon_9031', 'B-FOODON_00001287', 'B-FOODON_03301671', 'I-FOODON_03315647', 'B-NCBITaxon_3562', 'B-FOODON_03306766', 'B-FOODON_03305518', 'I-FOODON_03309457', 'I-NCBITaxon_29780', 'I-FOODON_03315498', 'I-FOODON_03307062', 'B-FOODON_03306867', 'B-NCBITaxon_3760', 'B-FOODON_03302458', 'B-FOODON_03301256', 'I-PATO_0000386', 'B-FOODON_03301630', 'B-FOODON_03301632', 'B-FOODON_03301244', 'B-UBERON_0002113', 'B-FOODON_03302713', 'I-NCBITaxon_4682', 'B-FOODON_03305428', 'B-FOODON_03307312', 'I-FOODON_03302111', 'B-CHEBI_33290', 'I-FOODON_03309832', 'I-FOODON_03316347', 'B-FOODON_03301585', 'I-FOODON_03301660', 'B-FOODON_03301397', 'B-FOODON_03306347', 'B-FOODON_03309554', 'B-FOODON_03316284', 'B-CHEBI_60004', 'I-FOODON_03307240', 'B-NCBITaxon_9031', 'B-NCBITaxon_4081', 'B-FOODON_03302946', 'I-FOODON_03301671', 'B-NCBITaxon_59895', 'I-FOODON_03317068', 'I-NCBITaxon_3562', 'B-NCBITaxon_89151', 'B-NCBITaxon_94328', 'I-FOODON_03307668', 'B-NCBITaxon_4006', 'B-FOODON_03301605', 'B-PATO_0001985', 'I-FOODON_03310351', 'I-FOODON_03420108', 'B-FOODON_03301701', 'I-NCBITaxon_4615', 'B-FOODON_03305617', 'B-FOODON_03302908', 'B-FOODON_03301175', 'I-FOODON_03305003', 'B-FOODON_03303225', 'B-FOODON_03411335', 'B-FOODON_03317034', 'B-FOODON_03411237', 'B-NCBITaxon_3493', 'B-FOODON_03305086', 'I-FOODON_03305428', 'B-FOODON_03302034', 'B-PO_0009001', 'I-FOODON_03301585', 'B-FOODON_03301564', 'B-FOODON_03301189', 'I-FOODON_03310387', 'B-FOODON_03302515', 'B-NCBITaxon_4329', 'B-FOODON_03302897', 'I-FOODON_03301256', 'B-FOODON_03301240', 'I-FOODON_03315258', 'B-FOODON_03307240', 'B-FOODON_03301577', 'I-FOODON_03301889', 'B-FOODON_03310795', 'B-FOODON_03301329', 'B-FOODON_03301802', 'I-FOODON_03411328', 'I-FOODON_03305417', 'B-FOODON_03301844', 'I-NCBITaxon_51238', 'I-FOODON_03305086', 'B-FOODON_03411044', 'B-FOODON_03306160', 'B-FOODON_03317654', 'B-FOODON_03307280', 'B-FOODON_03530020', 'I-FOODON_03305617', 'I-FOODON_03306160', 'B-FOODON_03315258', 'B-FOODON_03310086', 'I-FOODON_03530021', 'B-FOODON_03307062', 'I-FOODON_03301051', 'B-FOODON_03301468', 'B-FOODON_00002087', 'B-FOODON_03414363', 'B-FOODON_03315146', 'B-FOODON_03411669', 'I-FOODON_03307312', 'B-FOODON_03317068', 'I-FOODON_03311146', 'B-UBERON_0002107', 'I-FOODON_03301116', 'I-FOODON_03301329', 'B-FOODON_03302060', 'I-FOODON_03303508', 'I-FOODON_03301505', 'B-FOODON_03301455', 'B-FOODON_03301128', 'B-UBERON_0007378', 'B-FOODON_03317294', 'B-NCBITaxon_3755', 'B-NCBITaxon_381124', 'I-FOODON_03301217', 'B-UBERON_0036016', 'B-FOODON_03301619', 'B-FOODON_03305159', 'B-FOODON_03304564', 'B-FOODON_03315188', 'I-GAZ_00000558', 'I-FOODON_03301455', 'I-FOODON_03303225', 'B-FOODON_03310760', 'B-ancestro_0354', 'B-FOODON_03301105', 'I-FOODON_03306867', 'B-NCBITaxon_34199', 'B-FOODON_03305680', 'I-NCBITaxon_4113', 'B-FOODON_03302111', 'I-FOODON_00001287', 'B-NCBITaxon_23211', 'B-NCBITaxon_29780', 'B-FOODON_03301660', 'B-PATO_0000386', 'B-FOODON_03301889', 'I-FOODON_03301710', 'B-FOODON_03301710', 'I-FOODON_03302904', 'I-UBERON_0002113', 'B-FOODON_03304704', 'B-hancestro_0383', 'B-NCBITaxon_3747', 'B-NCBITaxon_37656', 'B-NCBITaxon_3888', 'B-FOODON_03302835', 'I-FOODON_03317294', 'B-FOODON_03315272', 'B-FOODON_03310290', 'I-FOODON_03311869', 'I-FOODON_03301441', 'B-NCBITaxon_39352', 'I-NCBITaxon_4081', 'B-FOODON_03301126', 'B-FOODON_03420108', 'B-FOODON_03302062', 'I-FOODON_03306766', 'I-FOODON_03304564', 'B-NCBITaxon_4615', 'I-FOODON_03430168', 'B-FOODON_03309462', 'I-FOODON_03316042', 'I-ancestro_0354', 'I-FOODON_03301304', 'I-FOODON_03309462', 'B-FOODON_03315025', 'I-FOODON_03302515', 'I-FOODON_03310795', 'B-FOODON_03315259', 'I-NCBITaxon_4039', 'B-FOODON_03420157', 'B-FOODON_03301440', 'B-GAZ_00000558', 'I-NCBITaxon_80379', 'B-FOODON_03430168', 'I-FOODON_03412974', 'B-NCBITaxon_117781', 'B-FOODON_03301116', 'B-NCBITaxon_32201', 'I-UBERON_0002107', 'B-FOODON_03315835', 'B-FOODON_03304010', 'B-NCBITaxon_3827', 'I-PATO_0001985', 'B-FOODON_03301304', 'B-NCBITaxon_51238', 'B-FOODON_03301672', 'B-FOODON_03315498', 'I-FOODON_03304042', 'B-NCBITaxon_4565', 'I-FOODON_03303659', 'B-FOODON_03310689', 'I-FOODON_03301605', 'I-FOODON_03301175', 'I-FOODON_03530217', 'B-FOODON_03301705', 'B-FOODON_03316042', 'B-NCBITaxon_4039', 'B-FOODON_03303886', 'B-FOODON_00001926', 'I-FOODON_03302772', 'I-FOODON_03310086', 'I-NCBITaxon_3747', 'I-NCBITaxon_3760', 'B-FOODON_03310387', 'B-FOODON_03305003', 'B-FOODON_03309832', 'I-FOODON_03301844', 'I-UBERON_0007378', 'I-FOODON_03301619', 'I-NCBITaxon_3827', 'I-FOODON_03305263', 'I-FOODON_03309554', 'B-FOODON_03310273', 'I-NCBITaxon_4329', 'B-FOODON_03302775', 'I-FOODON_03303380', 'B-FOODON_03412974', 'I-FOODON_03302062', 'I-FOODON_03301701', 'PAD'],\n",
        "    \"snomedct\": ['I-442681000124105', 'B-227592002', 'B-227757007', 'I-735030001', 'I-226551004', 'B-226855000', 'B-227418000', 'I-129559002', 'B-226562004', 'I-226726003', 'B-227218003', 'B-227239005', 'I-227219006', 'I-227215000', 'I-226928005', 'B-227411006', 'B-256443002', 'B-226888007', 'B-226863004', 'I-28647000', 'B-256307007', 'I-735248001', 'B-227282006', 'I-412065005', 'B-227549007', 'B-735336002', 'B-22836000', 'B-226041007', 'B-419420009', 'B-226559002', 'B-256354006', 'I-412066006', 'B-735249009', 'I-102264005', 'B-412061001', 'B-53410008', 'I-226838004', 'I-260184002', 'B-24515005', 'B-226587006', 'I-226855000', 'B-226802006', 'B-102262009', 'I-226802006', 'B-229908005', 'B-227436000', 'I-227519005', 'B-255621006', 'B-735009005', 'B-226493000', 'I-256350002', 'B-227362005', 'B-735049002', 'I-70813002', 'B-735106000', 'B-227400003', 'B-226639005', 'B-226849005', 'B-735050002', 'B-226753004', 'B-35748005', 'B-735048005', 'B-442891000124107', 'B-227407000', 'B-735248001', 'B-227430006', 'I-227282006', 'I-102262009', 'B-16313001', 'B-227553009', 'I-226849005', 'B-227612008', 'I-227436000', 'B-256329006', 'I-102261002', 'I-901000161107', 'I-226493000', 'I-226519000', 'I-226041007', 'I-735045008', 'I-444021000124105', 'I-443981000124106', 'B-226496008', 'I-227553009', 'B-9424004', 'I-735049002', 'I-226559002', 'I-67990004', 'B-226735005', 'B-736031006', 'B-256313003', 'O', 'I-226942002', 'I-226888007', 'B-227395004', 'B-256442007', 'B-227566009', 'B-420823005', 'I-256307007', 'B-41834005', 'I-735047000', 'B-734881000', 'I-412061001', 'B-226890008', 'B-29263009', 'B-226519000', 'I-67324005', 'I-63766005', 'B-226723006', 'I-227395004', 'I-230055000', 'B-256350002', 'B-412071004', 'I-41834005', 'I-9424004', 'I-226756007', 'B-227365007', 'B-735047000', 'B-735040003', 'I-227260004', 'I-256329006', 'B-226057007', 'B-227350006', 'B-227219006', 'B-735010000', 'B-226928005', 'B-412066006', 'B-227545001', 'B-70813002', 'B-412062008', 'B-278840001', 'B-227501001', 'B-226756007', 'B-735215001', 'B-227421003', 'B-226543002', 'B-226725004', 'I-443701000124100', 'I-89707004', 'I-734881000', 'I-226496008', 'B-735245003', 'B-227423000', 'I-735214002', 'B-443701000124100', 'B-736159005', 'B-226064009', 'I-53410008', 'B-444021000124105', 'B-227390009', 'B-735123009', 'B-226901000', 'B-226038003', 'B-260184002', 'B-227449005', 'B-89707004', 'B-227382009', 'I-227020009', 'B-226749001', 'B-443691000124100', 'I-226853007', 'B-226483007', 'B-227598003', 'I-227607007', 'I-278840001', 'I-227545001', 'B-226528004', 'B-226838004', 'B-226814003', 'B-226942002', 'I-72511004', 'B-256326004', 'B-412070003', 'I-412071004', 'I-227449005', 'I-227430006', 'B-226853007', 'B-328685004', 'I-229944000', 'B-227607007', 'I-229862008', 'B-28647000', 'I-442361000124108', 'I-226837009', 'I-35748005', 'B-226551004', 'I-230053007', 'B-72511004', 'B-227425007', 'I-226054000', 'I-762952008', 'B-608772009', 'B-226492005', 'I-226038003', 'B-735108004', 'I-735009005', 'B-443981000124106', 'B-735030001', 'I-444001000124100', 'B-226018004', 'B-226704004', 'I-227444000', 'B-412065005', 'B-226031009', 'B-735053000', 'B-442581000124106', 'B-412357001', 'B-227408005', 'B-227388008', 'I-226639005', 'B-226733003', 'I-412357001', 'I-256442007', 'B-229862008', 'B-227515004', 'I-256326004', 'I-419420009', 'B-227410007', 'B-227413009', 'B-226719003', 'I-713648000', 'B-226916002', 'B-735045008', 'I-29263009', 'B-227519005', 'I-443691000124100', 'B-226934003', 'B-227150003', 'B-102264005', 'B-230055000', 'B-226498009', 'I-226498009', 'I-22836000', 'B-227463004', 'I-226934003', 'B-256317002', 'I-226916002', 'B-256319004', 'I-226787009', 'B-608773004', 'B-442341000124109', 'B-63766005', 'I-16313001', 'I-256313003', 'B-901000161107', 'I-227592002', 'I-226647005', 'B-226604005', 'B-226726003', 'B-226769006', 'I-227362005', 'B-227215000', 'I-226831005', 'B-229948002', 'I-226516007', 'I-735215001', 'B-230053007', 'B-226019007', 'B-13577000', 'I-735053000', 'I-735340006', 'B-442751000124107', 'I-256354006', 'I-256443002', 'B-226837009', 'B-227689008', 'B-226054000', 'I-227757007', 'B-226516007', 'B-442681000124105', 'I-328685004', 'B-102261002', 'I-226753004', 'I-735211005', 'B-227260004', 'I-412070003', 'B-226647005', 'B-227020009', 'B-735042006', 'B-762952008', 'I-735042006', 'B-226787009', 'I-255621006', 'B-713648000', 'B-229887001', 'I-735245003', 'B-444001000124100', 'I-227501001', 'B-129559002', 'I-227400003', 'B-67990004', 'B-735211005', 'I-226814003', 'I-226749001', 'B-227722009', 'I-226955001', 'B-51905005', 'B-735340006', 'B-442861000124104', 'B-226831005', 'B-229944000', 'B-227444000', 'I-227612008', 'I-226543002', 'B-444161000124100', 'B-226955001', 'B-735213008', 'I-227388008', 'B-442811000124102', 'I-736159005', 'B-67324005', 'B-226740002', 'B-735214002', 'B-442361000124108', 'I-442341000124109', 'I-226492005', 'B-23182003', 'B-227606003', 'PAD']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UFJQTVttXMGi"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ucbj26cEt56x"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing dataset: hansard-parent\n",
            "Loading tag values for: hansard-parent\n",
            "Debugging Labels and Tag2Idx\n",
            "Missing labels: set()\n",
            "tag2idx: {'B-AG.01.a': 0, 'B-AG.01.i': 1, 'B-AF.12': 2, 'B-AG.01.r': 3, 'B-AE.08': 4, 'I-AG.01.l': 5, 'I-AG.01.f': 6, 'B-AG.01.w': 7, 'B-AF.10': 8, 'B-AG.01.p': 9, 'I-AG.01.r': 10, 'I-AG.01.p': 11, 'B-AG.01.t': 12, 'O': 13, 'B-AG.01.ad': 14, 'I-AG.01.o': 15, 'B-AG.01.j': 16, 'B-AG.01.ae': 17, 'B-AG.01.aa': 18, 'B-AG.01.ab': 19, 'B-AE.12': 20, 'I-AG.01.ab': 21, 'B-AG.01.g': 22, 'I-AG.01.t': 23, 'B-AG.01.f': 24, 'I-AE.13': 25, 'B-AG.01.h': 26, 'I-AG.01.aa': 27, 'B-AG.01.b': 28, 'B-AG.01.z': 29, 'B-AE.13': 30, 'I-AG.01.m': 31, 'B-AG.01.o': 32, 'B-AG.01': 33, 'B-AG.01.y': 34, 'I-AF.02': 35, 'B-AF.28': 36, 'B-AG.01.m': 37, 'I-AG.01.g': 38, 'I-AG.01.i': 39, 'B-AG.01.k': 40, 'B-AF.02': 41, 'I-AG.01.n': 42, 'I-AG.01.y': 43, 'I-AE.12': 44, 'B-AG.01.e': 45, 'I-AG.01.k': 46, 'B-AE.10': 47, 'I-AG.01.h': 48, 'I-AG.01.ae': 49, 'I-AF.10': 50, 'I-AG.01.z': 51, 'I-AG.01.a': 52, 'B-AG.01.d': 53, 'I-AE.10': 54, 'I-AG.01.j': 55, 'I-AG.01.ad': 56, 'B-AF.20': 57, 'I-AG.01': 58, 'B-AG.01.l': 59, 'I-AG.01.e': 60, 'I-AG.01.d': 61, 'B-AG.01.n': 62, 'PAD': 63}\n",
            "Validating Labels\n",
            "Resetting model for bert\n",
            "bert-model-hansard-parent-e6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_20461/2395197742.py:55: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data = pd.read_csv(train_path, encoding=\"latin1\", delimiter='\\t').fillna(method=\"ffill\")\n",
            "/tmp/ipykernel_20461/2395197742.py:56: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  test_data = pd.read_csv(test_path, encoding=\"latin1\", delimiter='\\t').fillna(method=\"ffill\")\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average train loss: 0.18706254502702616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "Epoch:  17%|█▋        | 1/6 [00:23<01:59, 23.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.06406048420620591\n",
            "Validation Accuracy: 0.9829656862745098\n",
            "Validation F1-Score: 0.6788370520622042\n",
            "\n",
            "Average train loss: 0.050430417328537584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  33%|███▎      | 2/6 [00:46<01:33, 23.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.028395902659547955\n",
            "Validation Accuracy: 0.9931295149638804\n",
            "Validation F1-Score: 0.8854469183607615\n",
            "\n",
            "Average train loss: 0.026968446967309108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  50%|█████     | 3/6 [01:10<01:10, 23.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.02176997156225537\n",
            "Validation Accuracy: 0.9949664602683178\n",
            "Validation F1-Score: 0.9284332688588006\n",
            "\n",
            "Average train loss: 0.017747707475356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  67%|██████▋   | 4/6 [01:34<00:47, 23.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.020236904732882977\n",
            "Validation Accuracy: 0.9951393188854488\n",
            "Validation F1-Score: 0.9343629343629344\n",
            "\n",
            "Average train loss: 0.014012251973631764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  83%|████████▎ | 5/6 [01:57<00:23, 23.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.01781043937233718\n",
            "Validation Accuracy: 0.9961016511867905\n",
            "Validation F1-Score: 0.9484268569575088\n",
            "\n",
            "Average train loss: 0.011824528810785648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 6/6 [02:21<00:00, 23.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.018190035424930483\n",
            "Validation Accuracy: 0.996077141382869\n",
            "Validation F1-Score: 0.9482200647249192\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/nilu/anaconda3/envs/nilu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resetting model for distilbert\n",
            "distilbert-model-hansard-parent-e6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 100\u001b[0m\n\u001b[1;32m     94\u001b[0m labels \u001b[38;5;241m=\u001b[39m [token_label_pair[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m token_label_pair \u001b[38;5;129;01min\u001b[39;00m tokenized_texts_and_labels]\n\u001b[1;32m     96\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m pad_sequences([tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(txt) \u001b[38;5;28;01mfor\u001b[39;00m txt \u001b[38;5;129;01min\u001b[39;00m tokenized_texts],\n\u001b[1;32m     97\u001b[0m                             maxlen\u001b[38;5;241m=\u001b[39mMAX_LEN, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncating\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m tags \u001b[38;5;241m=\u001b[39m pad_sequences([[tag2idx\u001b[38;5;241m.\u001b[39mget(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lab] \u001b[38;5;28;01mfor\u001b[39;00m lab \u001b[38;5;129;01min\u001b[39;00m labels],\n\u001b[1;32m    101\u001b[0m                     maxlen\u001b[38;5;241m=\u001b[39mMAX_LEN, value\u001b[38;5;241m=\u001b[39mtag2idx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPAD\u001b[39m\u001b[38;5;124m\"\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    102\u001b[0m                     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncating\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m attention_masks \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mfloat\u001b[39m(i \u001b[38;5;241m!=\u001b[39m tag2idx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPAD\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ii] \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m input_ids]\n\u001b[1;32m    106\u001b[0m tr_inputs, val_inputs, tr_tags, val_tags \u001b[38;5;241m=\u001b[39m train_test_split(input_ids, tags, \n\u001b[1;32m    107\u001b[0m                                                             random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2018\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/nilu/lib/python3.11/site-packages/keras/src/utils/data_utils.py:1132\u001b[0m, in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTruncating type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtruncating\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not understood\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# check `trunc` has expected shape\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m trunc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(trunc, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trunc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m!=\u001b[39m sample_shape:\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrunc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of sequence at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is different from expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1138\u001b[0m     )\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "base_path = '/home/nilu/FoodNer/data/'\n",
        "\n",
        "datasets={'hansard-parent': 'hansard-parent',\n",
        "  'food-classification':'food-classification',\n",
        "  \n",
        "  'hansard-closest':'hansard-closest',\n",
        "  'foodon': 'foodon',\n",
        "  'snomedct': 'snomedct'\n",
        "  #'longest-common-tag-part':'L',\n",
        "  # 'shortest-tag':'s', \n",
        "}\n",
        "\n",
        "# Loop through each dataset and process it\n",
        "for version_descriptive, model_version in datasets.items(): \n",
        "    # Construct the full path for train and test data\n",
        "    train_path = base_path + 'train-' + model_version + '.txt'\n",
        "    test_path = base_path + 'test-' + model_version + '.txt'\n",
        "    \n",
        "stored_models = {'bert': 'bert-base-cased',# BERT base model\n",
        "                 'distilbert': 'distilbert-base-uncased', # DistilBERT base model\n",
        "     \n",
        "    'roberta': 'roberta-base',  # RoBERTa base model\n",
        "      \n",
        "    # 'bioBert-standard': '/content/drive/My Drive/Colab Notebooks/data/biobert',\n",
        "    # 'bioBert-large': '/content/drive/My Drive/Colab Notebooks/data/biobert_large'\n",
        "}\n",
        "\n",
        "\n",
        "model_tags = {}\n",
        "\n",
        "\n",
        "train_header='tags'\n",
        "test_header='-DOCSTART-'\n",
        "label_adapter = get_label\n",
        "\n",
        "\n",
        "epochs = 6\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "FULL_FINETUNING = True\n",
        "\n",
        "\n",
        "# Loop through each dataset and process it\n",
        "for version_descriptive, model_version in datasets.items():\n",
        "    print()\n",
        "    print(f\"Processing dataset: {version_descriptive}\")\n",
        "    \n",
        "    \n",
        "\n",
        "    # Construct the full path for train and test data\n",
        "    train_path = base_path + 'train-' + model_version + '.txt'\n",
        "    test_path = base_path + 'test-' + model_version + '.txt'\n",
        "\n",
        "    # Initialize data\n",
        "    data = pd.read_csv(train_path, encoding=\"latin1\", delimiter='\\t').fillna(method=\"ffill\")\n",
        "    test_data = pd.read_csv(test_path, encoding=\"latin1\", delimiter='\\t').fillna(method=\"ffill\")\n",
        "\n",
        "    # Process BIO data\n",
        "    getter, sentences, tag_values, tag2idx, labels = process_bio(data, train_header, label_adapter)\n",
        "\n",
        "    # Load tag values for each dataset\n",
        "    if ds_tag_values.get(version_descriptive): \n",
        "        print('Loading tag values for:', version_descriptive)\n",
        "        tag_values = ds_tag_values.get(version_descriptive)\n",
        "        tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
        "    else:   \n",
        "        with open(version_descriptive + \".txt\", 'w') as a: \n",
        "            print(str(tag_values))\n",
        "            a.write(str(tag_values))\n",
        "            model_tags[version_descriptive] = tag_values\n",
        "    debug_labels_and_tag2idx(labels, tag2idx)\n",
        "    validate_labels(labels, tag2idx)\n",
        "\n",
        "    # Loop over each model\n",
        "    for model_prefix, load_model in stored_models.items():\n",
        "        reset_model(model_prefix)\n",
        "        model_name = model_prefix + '-model-' + version_descriptive + '-e' + str(epochs)\n",
        "        print(model_name)\n",
        "\n",
        "        # Load model and tokenizer dynamically\n",
        "        model, tokenizer = get_model_and_tokenizer(load_model, num_labels=len(tag2idx))\n",
        "        model.to(device)\n",
        "        \n",
        "\n",
        "\n",
        "        # Tokenize and prepare data for the specific model\n",
        "        tokenized_texts_and_labels = [\n",
        "            tokenize_and_preserve_labels(sent, labs, tokenizer)\n",
        "            for sent, labs in zip(sentences, labels)\n",
        "        ]\n",
        "        \n",
        "\n",
        "        tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
        "        labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]\n",
        "\n",
        "        input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                                    maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "\n",
        "        tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
        "                            maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                            dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "        attention_masks = [[float(i != tag2idx[\"PAD\"]) for i in ii] for ii in input_ids]\n",
        "\n",
        "        tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
        "                                                                    random_state=2018, test_size=0.1)\n",
        "        tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                                    random_state=2018, test_size=0.1)\n",
        "\n",
        "        tr_inputs = torch.tensor(tr_inputs).to(device)\n",
        "        val_inputs = torch.tensor(val_inputs).to(device)\n",
        "        tr_tags = torch.tensor(tr_tags).to(device)\n",
        "        val_tags = torch.tensor(val_tags).to(device)\n",
        "        tr_masks = torch.tensor(tr_masks).to(device)\n",
        "        val_masks = torch.tensor(val_masks).to(device)\n",
        "\n",
        "\n",
        "        train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "        train_sampler = RandomSampler(train_data)\n",
        "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "        valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "        valid_sampler = SequentialSampler(valid_data)\n",
        "        valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n",
        "        \n",
        "\n",
        "\n",
        "        if FULL_FINETUNING:\n",
        "            param_optimizer = list(model.named_parameters())\n",
        "            no_decay = ['bias', 'gamma', 'beta']\n",
        "            optimizer_grouped_parameters = [\n",
        "                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "                'weight_decay_rate': 0.01},\n",
        "                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "                'weight_decay_rate': 0.0}\n",
        "            ]\n",
        "        else:\n",
        "            param_optimizer = list(model.classifier.named_parameters()) \n",
        "            optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "        optimizer = AdamW(\n",
        "            optimizer_grouped_parameters,        \n",
        "            lr=3e-5,\n",
        "            eps=1e-8\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        # Total number of training steps is number of batches * number of epochs.\n",
        "        total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "        # Create the learning rate scheduler.\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, \n",
        "            num_warmup_steps=0,\n",
        "            \n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "\n",
        "        ## Store the average loss after each epoch so we can plot them.\n",
        "        loss_values, validation_loss_values = [], []\n",
        "\n",
        "        for _ in trange(epochs, desc=\"Epoch\"):\n",
        "            # ========================================\n",
        "            #               Training\n",
        "            # ========================================\n",
        "            # Perform one full pass over the training set.\n",
        "            \n",
        "            # Put the model into training mode.\n",
        "            model.train()\n",
        "            # Reset the total loss for this epoch.\n",
        "            total_loss = 0\n",
        "\n",
        "            # Training loop\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                # add batch to gpu\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "                b_input_ids, b_input_mask, b_labels = batch\n",
        "                # Always clear any previously calculated gradients before performing a backward pass.\n",
        "                model.zero_grad()\n",
        "                # forward pass\n",
        "                # This will return the loss (rather than the model output)\n",
        "                # because we have provided the `labels`.\n",
        "                 #Conditional model call\n",
        "                if 'distilbert' in model_prefix:\n",
        "                    # For DistilBERT\n",
        "                    outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "                else:\n",
        "                    # For BERT and RoBERTa\n",
        "                    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "                #outputs = model(b_input_ids, token_type_ids=None,\n",
        "                                #attention_mask=b_input_mask, labels=b_labels)\n",
        "                # get the loss\n",
        "                loss = outputs[0]\n",
        "                # Perform a backward pass to calculate the gradients.\n",
        "                loss.backward()\n",
        "                # track train loss\n",
        "                total_loss += loss.item()    \n",
        "                # Clip the norm of the gradient\n",
        "                # This is to help prevent the \"exploding gradients\" problem.\n",
        "                torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "                # update parameters\n",
        "                optimizer.step()\n",
        "                # Update the learning rate.\n",
        "                scheduler.step()\n",
        "                \n",
        "            # Calculate the average loss over the training data.\n",
        "            avg_train_loss = total_loss / len(train_dataloader)\n",
        "            print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "            \n",
        "            # Store the loss value for plotting the learning curve.\n",
        "            loss_values.append(avg_train_loss)\n",
        "            \n",
        "            \n",
        "            # ========================================\n",
        "            #               Validation\n",
        "            # ========================================\n",
        "            # After the completion of each training epoch, measure our performance on\n",
        "            # our validation set.\n",
        "            \n",
        "            # Put the model into evaluation mode\n",
        "            model.eval()\n",
        "            # Reset the validation loss for this epoch.\n",
        "            eval_loss, eval_accuracy = 0, 0\n",
        "            nb_eval_steps, nb_eval_examples = 0, 0\n",
        "            predictions , true_labels = [], []\n",
        "            \n",
        "            for batch in valid_dataloader:\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "                b_input_ids, b_input_mask, b_labels = batch\n",
        "                \n",
        "                # Telling the model not to compute or store gradients,\n",
        "                # saving memory and speeding up validation\n",
        "                with torch.no_grad():\n",
        "                    if 'distilbert' in model_prefix:\n",
        "                        # For DistilBERT\n",
        "                        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "                    else:\n",
        "                        # For BERT and RoBERTa\n",
        "                        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "                    # Forward pass, calculate logit predictions.\n",
        "                    # This will return the logits rather than the loss because we have not provided labels.\n",
        "                    #outputs = model(b_input_ids, token_type_ids=None,\n",
        "                                    #attention_mask=b_input_mask, labels=b_labels)\n",
        "                # Move logits and labels to CPU\n",
        "                logits = outputs[1].detach().cpu().numpy()\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "                \n",
        "                # Calculate the accuracy for this batch of test sentences.\n",
        "                eval_loss += outputs[0].mean().item()\n",
        "                eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "                predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "                true_labels.append(label_ids)\n",
        "                \n",
        "                nb_eval_examples += b_input_ids.size(0)\n",
        "                nb_eval_steps += 1\n",
        "            \n",
        "            eval_loss = eval_loss / nb_eval_steps\n",
        "            validation_loss_values.append(eval_loss)\n",
        "            print(\"Validation loss: {}\".format(eval_loss))\n",
        "            print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "            #pred_tags = [tag_values[p_i] for p in predictions for p_i in p]\n",
        "            pred_tags = [[tag_values[p_i] for p_i in p] for p in predictions]\n",
        "            valid_tags = [[tag_values[l_ii] for l_ii in l_i] for l in true_labels for l_i in l]\n",
        "\n",
        "            #valid_tags = [tag_values[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "            \n",
        "\n",
        "            print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n",
        "            print()\n",
        "\n",
        "\n",
        "        plt.clf()\n",
        "\n",
        "        # Use plot styling from seaborn.\n",
        "        sns.set(style='darkgrid')\n",
        "\n",
        "        # Increase the plot size and font size.\n",
        "        sns.set(font_scale=1.5)\n",
        "        plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "        # Plot the learning curve.\n",
        "        plt.plot(loss_values, 'b-o', label=\"training loss\")\n",
        "        plt.plot(validation_loss_values, 'r-o', label=\"validation loss\")\n",
        "\n",
        "        # Label the plot.\n",
        "        plt.title(\"Learning curve\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.savefig(model_name+'.png', format='png')\n",
        "\n",
        "\n",
        "\n",
        "        # Evaluation\n",
        "\n",
        "        train_labels = labels\n",
        "        getter, sentences, m, n, labels = process_bio(test_data, test_header, label_adapter)\n",
        "\n",
        "        ix=0\n",
        "        correct = labels\n",
        "        predicted = []\n",
        "\n",
        "        for s in sentences:\n",
        "            test_sentence = \" \".join(s)\n",
        "        \n",
        "            tokenized_sentence = tokenizer.encode(test_sentence)\n",
        "            input_ids = torch.tensor([tokenized_sentence]).to(device)\n",
        "\n",
        "        \n",
        "            with torch.no_grad():\n",
        "                output = model(input_ids)\n",
        "            label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "\n",
        "            tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "            new_tokens, new_labels = [], []\n",
        "            for token, label_idx in zip(tokens, label_indices[0]):\n",
        "                if token.startswith(\"##\"):\n",
        "                    new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "                else:\n",
        "                    new_labels.append(tag_values[label_idx])\n",
        "                    new_tokens.append(token)\n",
        "\n",
        "\n",
        "            pred=[]\n",
        "            for wi in range(0, len(labels[ix])):\n",
        "                pred.append(new_labels[wi+1])\n",
        "                \n",
        "            \n",
        "            predicted.append(pred)\n",
        "            ix+=1\n",
        "\n",
        "        correct_flat = [item for sublist in correct for item in sublist]\n",
        "        predicted_flat = [item for sublist in predicted for item in sublist]\n",
        "\n",
        "\n",
        "        target_names = set([item for item in itertools.chain(correct_flat, predicted_flat)])\n",
        "        len(target_names)\n",
        "        with open(model_name+'.log', 'w+') as log: \n",
        "            log.write(classification_report(correct_flat, predicted_flat, target_names=target_names))\n",
        "\n",
        "        torch.save(model.state_dict(), model_name+'.bin')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FoodNER.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "model_study",
      "language": "python",
      "name": "nilu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
